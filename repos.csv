"user","repo","url","stars","description","topics","repoLink","commits"
"scrapy","scrapy","https://github.com/scrapy/scrapy",48938,"Scrapy, a fast high-level web crawling & scraping framework for Python.","[""python"",""crawler"",""framework"",""scraping"",""crawling"",""web-scraping"",""hacktoberfest"",""web-scraping-python""]","/scrapy/scrapy",10172
"gocolly","colly","https://github.com/gocolly/colly",20920,"Elegant Scraper and Crawler Framework for Golang","[""go"",""golang"",""crawler"",""scraper"",""framework"",""spider"",""scraping"",""crawling""]","/gocolly/colly",653
"codelucas","newspaper","https://github.com/codelucas/newspaper",13191,"News, full-text, and article metadata extraction in Python 3. Advanced docs:","[""python"",""crawler"",""scraper"",""news"",""crawling"",""news-aggregator""]","/codelucas/newspaper",651
"apify","crawlee","https://github.com/apify/crawlee",9213,"Crawleeâ€”A web scraping and browser automation library for Node.js that helps you build reliable crawlers. Fast.","[""nodejs"",""javascript"",""npm"",""crawler"",""scraper"",""automation"",""typescript"",""web-crawler"",""headless"",""scraping"",""crawling"",""web-scraping"",""web-crawling"",""headless-chrome"",""apify"",""puppeteer"",""playwright""]","/apify/crawlee",3887
"lorien","awesome-web-scraping","https://github.com/lorien/awesome-web-scraping",6017,"List of libraries, tools and APIs for web scraping and data processing.","[""crawler"",""spider"",""scraping"",""crawling"",""web-scraping"",""captcha-recaptcha"",""webscraping"",""crawling-framework"",""scraping-framework"",""captcha-bypass"",""scraping-tool"",""crawling-tool"",""scraping-python"",""crawling-python""]","/lorien/awesome-web-scraping",494
"MontFerret","ferret","https://github.com/MontFerret/ferret",5492,"Declarative web scraping","[""go"",""cli"",""golang"",""crawler"",""chrome"",""data-mining"",""scraper"",""library"",""tool"",""dsl"",""scraping"",""crawling"",""query-language"",""scraping-websites"",""hacktoberfest"",""cdp"",""hacktoberfest2021""]","/MontFerret/ferret",843
"yujiosaka","headless-chrome-crawler","https://github.com/yujiosaka/headless-chrome-crawler",5417,"Distributed crawler powered by Headless Chrome","[""jquery"",""crawler"",""chrome"",""scraper"",""promise"",""scraping"",""crawling"",""chromium"",""headless-chrome"",""puppeteer""]","/yujiosaka/headless-chrome-crawler",666
"go-rod","rod","https://github.com/go-rod/rod",4261,"A Devtools driver for web automation and scraping","[""testing"",""go"",""golang"",""scraper"",""automation"",""web"",""chrome-devtools"",""headless"",""devtools"",""crawling"",""web-scraping"",""cdp"",""chrome-headless"",""rod"",""chrome-devtools-protocol"",""devtools-protocol"",""gorod""]","/go-rod/rod",1260
"hakluke","hakrawler","https://github.com/hakluke/hakrawler",3993,"Simple, fast web crawler designed for easy, quick discovery of endpoints and assets within a web application","[""osint"",""crawling"",""hacking"",""pentesting"",""recon"",""bugbounty"",""reconnaissance""]","/hakluke/hakrawler",234
"hardkoded","puppeteer-sharp","https://github.com/hardkoded/puppeteer-sharp",2862,"Headless Chrome .NET API","[""crawler"",""chrome"",""automation"",""csharp"",""crawling"",""chromium"",""e2e"",""webautomation"",""e2e-testing"",""puppeteer""]","/hardkoded/puppeteer-sharp",1071
"apache","nutch","https://github.com/apache/nutch",2691,"Apache Nutch is an extensible and scalable web crawler","[""java"",""hadoop"",""web-crawler"",""nutch"",""crawling"",""apache""]","/apache/nutch",3389
"lorien","grab","https://github.com/lorien/grab",2323,"Web Scraping Framework","[""python"",""crawler"",""framework"",""spider"",""asynchronous"",""network"",""python-library"",""scraping"",""crawling"",""http-client"",""python3"",""web-scraping"",""pycurl"",""urllib3""]","/lorien/grab",2489
"transitive-bullshit","awesome-puppeteer","https://github.com/transitive-bullshit/awesome-puppeteer",2219,"A curated list of awesome puppeteer resources.","[""automation"",""awesome"",""scraping"",""crawling"",""awesome-list"",""headless-chrome"",""puppeteer""]","/transitive-bullshit/awesome-puppeteer",120
"zorlan","skycaiji","https://github.com/zorlan/skycaiji",1766,"è“å¤©é‡‡é›†å™¨æ˜¯ä¸€æ¬¾å¼€æºå…è´¹çš„çˆ¬è™«ç³»ç»Ÿï¼Œä»…éœ€ç‚¹é€‰ç¼–è¾‘è§„åˆ™å³å¯é‡‡é›†æ•°æ®ï¼Œå¯è¿è¡Œåœ¨æœ¬åœ°ã€è™šæ‹Ÿä¸»æœºæˆ–äº‘æœåŠ¡å™¨ä¸­ï¼Œå‡ ä¹èƒ½é‡‡é›†æ‰€æœ‰ç±»å‹çš„ç½‘é¡µï¼Œæ— ç¼å¯¹æ¥å„ç±»CMSå»ºç«™ç¨‹åºï¼Œå…ç™»å½•å®æ—¶å‘å¸ƒæ•°æ®ï¼Œå…¨è‡ªåŠ¨æ— éœ€äººå·¥å¹²é¢„ï¼æ˜¯ç½‘é¡µå¤§æ•°æ®é‡‡é›†è½¯ä»¶ä¸­å®Œå…¨è·¨å¹³å°çš„äº‘ç«¯çˆ¬è™«ç³»ç»Ÿ","[""php"",""crawler"",""spider"",""crawling"",""webcrawler""]","/zorlan/skycaiji",19
"roach-php","core","https://github.com/roach-php/core",1263,"The complete web scraping toolkit for PHP.","[""php"",""crawling"",""web-scraping""]","/roach-php/core",251
"edoardottt","cariddi","https://github.com/edoardottt/cariddi",1143,"Take a list of domains, crawl urls and scan for endpoints, secrets, api keys, file extensions, tokens and more","[""go"",""golang"",""security"",""crawler"",""scraper"",""osint"",""crawling"",""penetration-testing"",""infosec"",""pentesting"",""recon"",""bugbounty"",""hacktoberfest"",""security-tools"",""endpoints"",""reconnaissance"",""secret-keys"",""endpoint-discovery"",""secrets-detection"",""asset-finder""]","/edoardottt/cariddi",549
"lorey","mlscraper","https://github.com/lorey/mlscraper",1073,"ğŸ¤– Scrape data from HTML websites automatically by just providing examples","[""html"",""crawler"",""machine-learning"",""scraper"",""scraping"",""crawling"",""crawler-python"",""extraction-engine""]","/lorey/mlscraper",124
"needleworm","bhban_rpa","https://github.com/needleworm/bhban_rpa",883,"<6ê°œì›” ì¹˜ ì—…ë¬´ë¥¼ í•˜ë£¨ ë§Œì— ëë‚´ëŠ” ì—…ë¬´ ìë™í™”(ìƒëŠ¥ì¶œíŒì‚¬, 2020)>ì˜ ì˜ˆì œ ì½”ë“œì…ë‹ˆë‹¤. íŒŒì´ì¬ì„ í•œ ë²ˆë„ ë°°ì›Œë³¸ ì  ì—†ëŠ” ë¶„ë“¤ì„ ìœ„í•œ ì˜ˆì œì´ë©°, ì—‘ì…€ë¶€í„° ë””ìì¸, ë§¤í¬ë¡œ, í¬ë¡¤ë§ê¹Œì§€ ì—…ë¬´ ìë™í™”ì™€ ê´€ë ¨ëœ ë‹¤ì–‘í•œ ë¶„ì•¼ ì˜ˆì œê°€ ì œê³µë©ë‹ˆë‹¤.","[""python"",""education"",""design"",""automation"",""crawling"",""rpa""]","/needleworm/bhban_rpa",316
"NateScarlet","holiday-cn","https://github.com/NateScarlet/holiday-cn",863,"ğŸ“…ğŸ‡¨ğŸ‡³ä¸­å›½æ³•å®šèŠ‚å‡æ—¥æ•°æ® è‡ªåŠ¨æ¯æ—¥æŠ“å–å›½åŠ¡é™¢å…¬å‘Š","[""data"",""natural-language-processing"",""crawling"",""china"",""holiday""]","/NateScarlet/holiday-cn",329
"clemfromspace","scrapy-selenium","https://github.com/clemfromspace/scrapy-selenium",842,"Scrapy middleware to handle javascript pages using selenium","[""crawling"",""selenium"",""scrapy""]","/clemfromspace/scrapy-selenium",31