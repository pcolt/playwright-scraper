"user","repo","url","stars","description","topics"
"scrapy","scrapy","https://github.com/scrapy/scrapy",48937,"Scrapy, a fast high-level web crawling & scraping framework for Python.","[""python"",""crawler"",""framework"",""scraping"",""crawling"",""web-scraping"",""hacktoberfest"",""web-scraping-python""]"
"gocolly","colly","https://github.com/gocolly/colly",20920,"Elegant Scraper and Crawler Framework for Golang","[""go"",""golang"",""crawler"",""scraper"",""framework"",""spider"",""scraping"",""crawling""]"
"codelucas","newspaper","https://github.com/codelucas/newspaper",13190,"News, full-text, and article metadata extraction in Python 3. Advanced docs:","[""python"",""crawler"",""scraper"",""news"",""crawling"",""news-aggregator""]"
"apify","crawlee","https://github.com/apify/crawlee",9213,"Crawleeâ€”A web scraping and browser automation library for Node.js that helps you build reliable crawlers. Fast.","[""nodejs"",""javascript"",""npm"",""crawler"",""scraper"",""automation"",""typescript"",""web-crawler"",""headless"",""scraping"",""crawling"",""web-scraping"",""web-crawling"",""headless-chrome"",""apify"",""puppeteer"",""playwright""]"
"lorien","awesome-web-scraping","https://github.com/lorien/awesome-web-scraping",6017,"List of libraries, tools and APIs for web scraping and data processing.","[""crawler"",""spider"",""scraping"",""crawling"",""web-scraping"",""captcha-recaptcha"",""webscraping"",""crawling-framework"",""scraping-framework"",""captcha-bypass"",""scraping-tool"",""crawling-tool"",""scraping-python"",""crawling-python""]"
"MontFerret","ferret","https://github.com/MontFerret/ferret",5492,"Declarative web scraping","[""go"",""cli"",""golang"",""crawler"",""chrome"",""data-mining"",""scraper"",""library"",""tool"",""dsl"",""scraping"",""crawling"",""query-language"",""scraping-websites"",""hacktoberfest"",""cdp"",""hacktoberfest2021""]"
"yujiosaka","headless-chrome-crawler","https://github.com/yujiosaka/headless-chrome-crawler",5417,"Distributed crawler powered by Headless Chrome","[""jquery"",""crawler"",""chrome"",""scraper"",""promise"",""scraping"",""crawling"",""chromium"",""headless-chrome"",""puppeteer""]"
"go-rod","rod","https://github.com/go-rod/rod",4260,"A Devtools driver for web automation and scraping","[""testing"",""go"",""golang"",""scraper"",""automation"",""web"",""chrome-devtools"",""headless"",""devtools"",""crawling"",""web-scraping"",""cdp"",""chrome-headless"",""rod"",""chrome-devtools-protocol"",""devtools-protocol"",""gorod""]"
"hakluke","hakrawler","https://github.com/hakluke/hakrawler",3993,"Simple, fast web crawler designed for easy, quick discovery of endpoints and assets within a web application","[""osint"",""crawling"",""hacking"",""pentesting"",""recon"",""bugbounty"",""reconnaissance""]"
"hardkoded","puppeteer-sharp","https://github.com/hardkoded/puppeteer-sharp",2862,"Headless Chrome .NET API","[""crawler"",""chrome"",""automation"",""csharp"",""crawling"",""chromium"",""e2e"",""webautomation"",""e2e-testing"",""puppeteer""]"
"apache","nutch","https://github.com/apache/nutch",2691,"Apache Nutch is an extensible and scalable web crawler","[""java"",""hadoop"",""web-crawler"",""nutch"",""crawling"",""apache""]"
"lorien","grab","https://github.com/lorien/grab",2323,"Web Scraping Framework","[""python"",""crawler"",""framework"",""spider"",""asynchronous"",""network"",""python-library"",""scraping"",""crawling"",""http-client"",""python3"",""web-scraping"",""pycurl"",""urllib3""]"
"transitive-bullshit","awesome-puppeteer","https://github.com/transitive-bullshit/awesome-puppeteer",2219,"A curated list of awesome puppeteer resources.","[""automation"",""awesome"",""scraping"",""crawling"",""awesome-list"",""headless-chrome"",""puppeteer""]"
"zorlan","skycaiji","https://github.com/zorlan/skycaiji",1766,"è“å¤©é‡‡é›†å™¨æ˜¯ä¸€æ¬¾å¼€æºå…è´¹çš„çˆ¬è™«ç³»ç»Ÿï¼Œä»…éœ€ç‚¹é€‰ç¼–è¾‘è§„åˆ™å³å¯é‡‡é›†æ•°æ®ï¼Œå¯è¿è¡Œåœ¨æœ¬åœ°ã€è™šæ‹Ÿä¸»æœºæˆ–äº‘æœåŠ¡å™¨ä¸­ï¼Œå‡ ä¹èƒ½é‡‡é›†æ‰€æœ‰ç±»å‹çš„ç½‘é¡µï¼Œæ— ç¼å¯¹æ¥å„ç±»CMSå»ºç«™ç¨‹åºï¼Œå…ç™»å½•å®æ—¶å‘å¸ƒæ•°æ®ï¼Œå…¨è‡ªåŠ¨æ— éœ€äººå·¥å¹²é¢„ï¼æ˜¯ç½‘é¡µå¤§æ•°æ®é‡‡é›†è½¯ä»¶ä¸­å®Œå…¨è·¨å¹³å°çš„äº‘ç«¯çˆ¬è™«ç³»ç»Ÿ","[""php"",""crawler"",""spider"",""crawling"",""webcrawler""]"
"roach-php","core","https://github.com/roach-php/core",1263,"The complete web scraping toolkit for PHP.","[""php"",""crawling"",""web-scraping""]"
"edoardottt","cariddi","https://github.com/edoardottt/cariddi",1143,"Take a list of domains, crawl urls and scan for endpoints, secrets, api keys, file extensions, tokens and more","[""go"",""golang"",""security"",""crawler"",""scraper"",""osint"",""crawling"",""penetration-testing"",""infosec"",""pentesting"",""recon"",""bugbounty"",""hacktoberfest"",""security-tools"",""endpoints"",""reconnaissance"",""secret-keys"",""endpoint-discovery"",""secrets-detection"",""asset-finder""]"
"lorey","mlscraper","https://github.com/lorey/mlscraper",1073,"ğŸ¤– Scrape data from HTML websites automatically by just providing examples","[""html"",""crawler"",""machine-learning"",""scraper"",""scraping"",""crawling"",""crawler-python"",""extraction-engine""]"
"needleworm","bhban_rpa","https://github.com/needleworm/bhban_rpa",883,"<6ê°œì›” ì¹˜ ì—…ë¬´ë¥¼ í•˜ë£¨ ë§Œì— ëë‚´ëŠ” ì—…ë¬´ ìë™í™”(ìƒëŠ¥ì¶œíŒì‚¬, 2020)>ì˜ ì˜ˆì œ ì½”ë“œì…ë‹ˆë‹¤. íŒŒì´ì¬ì„ í•œ ë²ˆë„ ë°°ì›Œë³¸ ì  ì—†ëŠ” ë¶„ë“¤ì„ ìœ„í•œ ì˜ˆì œì´ë©°, ì—‘ì…€ë¶€í„° ë””ìì¸, ë§¤í¬ë¡œ, í¬ë¡¤ë§ê¹Œì§€ ì—…ë¬´ ìë™í™”ì™€ ê´€ë ¨ëœ ë‹¤ì–‘í•œ ë¶„ì•¼ ì˜ˆì œê°€ ì œê³µë©ë‹ˆë‹¤.","[""python"",""education"",""design"",""automation"",""crawling"",""rpa""]"
"NateScarlet","holiday-cn","https://github.com/NateScarlet/holiday-cn",863,"ğŸ“…ğŸ‡¨ğŸ‡³ä¸­å›½æ³•å®šèŠ‚å‡æ—¥æ•°æ® è‡ªåŠ¨æ¯æ—¥æŠ“å–å›½åŠ¡é™¢å…¬å‘Š","[""data"",""natural-language-processing"",""crawling"",""china"",""holiday""]"
"clemfromspace","scrapy-selenium","https://github.com/clemfromspace/scrapy-selenium",842,"Scrapy middleware to handle javascript pages using selenium","[""crawling"",""selenium"",""scrapy""]"
"iawia002","Lulu","https://github.com/iawia002/Lulu",812,"[Unmaintained] A simple and clean video/music/image downloader ğŸ‘¾","[""python"",""crawler"",""scraper"",""downloader"",""video"",""scraping"",""crawling"",""python3""]"
"scrapinghub","scrapyrt","https://github.com/scrapinghub/scrapyrt",791,"HTTP API for Scrapy spiders","[""python"",""crawler"",""scraper"",""crawling"",""twisted"",""scrapy"",""webcrawler"",""hacktoberfest"",""webcrawling"",""hacktoberfest2021""]"
"elixir-crawly","crawly","https://github.com/elixir-crawly/crawly",768,"Crawly, a high-level web crawling & scraping framework for Elixir.","[""crawler"",""scraper"",""erlang"",""elixir"",""spider"",""scraping"",""crawling"",""extract-data"",""scraping-websites""]"
"MorvanZhou","easy-scraping-tutorial","https://github.com/MorvanZhou/easy-scraping-tutorial",732,"Simple but useful Python web scraping tutorial code.","[""crawler"",""regex"",""scraping"",""crawling"",""requests"",""asyncio"",""scrapy"",""beautifulsoup"",""distributed-scraper"",""urllib""]"
"slotix","dataflowkit","https://github.com/slotix/dataflowkit",620,"Extract structured data from web sites. Web sites scraping.","[""go"",""golang"",""scraper"",""headless"",""scraping"",""crawling"",""golang-library"",""extract-data"",""scraping-websites"",""cdp"",""chrome-fetcher""]"
"essandess","isp-data-pollution","https://github.com/essandess/isp-data-pollution",541,"ISP Data Pollution to Protect Private Browsing History with Obfuscation","[""data"",""privacy"",""obfuscation"",""web"",""crawling"",""data-analytics"",""privacy-enhancing-technologies""]"
"mishakorzik","AdminHack","https://github.com/mishakorzik/AdminHack",519,"today we will hack the admin panel of the site.","[""linux"",""website"",""crawling"",""cpanel"",""termux"",""kali-linux"",""admin-finder"",""admin-panel"",""hacking-tool"",""cpanl-finder"",""directory-bruteforce"",""website-hacking"",""termux-tool"",""termux-hacking"",""website-hacking-methods"",""websitehacking"",""allhackingtools"",""admin-hack"",""admin-website-hack""]"
"bluet","proxybroker2","https://github.com/bluet/proxybroker2",515,"The New (auto rotate) Proxy [Finder | Checker | Server]. HTTP(S) & SOCKS ğŸ­","[""crawler"",""privacy"",""proxy"",""crawling"",""proxy-server"",""http-proxy"",""https-proxy"",""socks"",""proxies"",""anonymity"",""anonymous"",""proxypool"",""proxy-list"",""hacktoberfest"",""proxychains"",""proxy-checker""]"
"crawljax","crawljax","https://github.com/crawljax/crawljax",496,"Crawljax","[""javascript"",""crawler"",""dom"",""dynamic"",""crawling"",""test-generation"",""web-testing"",""web-analysis"",""event-driven-crawling""]"
"scrapinghub","spidermon","https://github.com/scrapinghub/spidermon",485,"Scrapy Extension for monitoring spiders execution.","[""testing"",""monitoring"",""scraping"",""crawling"",""spiders"",""hacktoberfest"",""monitoring-tool"",""scrapinghub""]"
"zhuyingda","webster","https://github.com/zhuyingda/webster",464,"a reliable high-level web crawling & scraping framework for Node.js.","[""nodejs"",""javascript"",""crawler"",""spider"",""javascript-framework"",""crawling"",""chromium"",""automation-ui"",""nodejs-framework"",""automation-test"",""headless-chrome"",""scraping-framework"",""puppeteer""]"
"josephlimtech","linkedin-profile-scraper","https://github.com/josephlimtech/linkedin-profile-scraper",389,"ğŸ•µï¸â€â™‚ï¸ LinkedIn profile scraper returning structured profile data in JSON.","[""nodejs"",""json"",""crawler"",""scraper"",""spider"",""linkedin"",""scraping"",""crawling"",""expressjs"",""linkedin-profile"",""scrapers"",""scraping-websites"",""linkedin-bot"",""website-scraper"",""profile-data"",""linkedin-scraper"",""linkedin-crawler"",""puppeteer"",""linkedin-scraping"",""linkedin-profile-scraper""]"
"Florents-Tselai","WarcDB","https://github.com/Florents-Tselai/WarcDB",377,"WarcDB: Web crawl data as SQLite databases.","[""cli"",""database"",""sqlite"",""crawling"",""warc"",""web-archiving"",""web-data""]"
"mhmdiaa","second-order","https://github.com/mhmdiaa/second-order",338,"Second-order subdomain takeover scanner","[""security"",""crawler"",""mapping"",""crawling"",""wordlist"",""penetration-testing"",""infosec"",""pentesting"",""recon"",""wordlist-generator"",""security-tools"",""web-application-security"",""reconnaissance"",""penetration-testing-tools""]"
"rivermont","spidy","https://github.com/rivermont/spidy",315,"The simple, easy to use command line web crawler.","[""python"",""crawler"",""web-crawler"",""crawling"",""python3"",""web-spider""]"
"l4rm4nd","LinkedInDumper","https://github.com/l4rm4nd/LinkedInDumper",310,"Python 3 script to dump/scrape/extract company employees from LinkedIn API","[""osint"",""spider"",""linkedin"",""scraping"",""crawling"",""python3"",""employees"",""extracting""]"
"stopstalk","stopstalk-deployment","https://github.com/stopstalk/stopstalk-deployment",306,"Stop stalking and start StopStalking ğŸ˜‰","[""python"",""aws"",""crawling"",""codechef"",""spoj"",""uva"",""competitive-programming"",""hackerrank"",""codeforces"",""web2py"",""materializecss"",""hackerearth"",""atcoder"",""programming-contests"",""hacktoberfest"",""timus"",""stopstalk""]"
"Malwarize","webpalm","https://github.com/Malwarize/webpalm",297,"WebPalm is a powerful command-line tool for website mapping and web scraping. With its recursive approach, it can generate a complete tree of all webpages and their links on a website. It can also extract data from the body of each page using regular expressions, making it an ideal tool for web scraping and data extraction.","[""go"",""golang"",""crawler"",""osint"",""spider"",""hack"",""tool"",""crawling"",""redteam""]"
"alephdata","memorious","https://github.com/alephdata/memorious",297,"Lightweight web scraping toolkit for documents and structured data.","[""scraping"",""crawling"",""scraping-framework""]"
"infinitbyte","gopa","https://github.com/infinitbyte/gopa",296,"GOPA, a spider written in Golang, for Elasticsearch. DEMO: http://index.elasticsearch.cn","[""lightweight"",""elasticsearch"",""crawler"",""spider"",""web-crawler"",""scraping"",""crawling"",""web-scraping"",""web-spider""]"