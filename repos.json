[{"user":"scrapy","repo":"scrapy","url":"https://github.com/scrapy/scrapy","stars":48962,"description":"Scrapy, a fast high-level web crawling & scraping framework for Python.","topics":["python","crawler","framework","scraping","crawling","web-scraping","hacktoberfest","web-scraping-python"],"repoLink":"/scrapy/scrapy","commits":10172},{"user":"gocolly","repo":"colly","url":"https://github.com/gocolly/colly","stars":20936,"description":"Elegant Scraper and Crawler Framework for Golang","topics":["go","golang","crawler","scraper","framework","spider","scraping","crawling"],"repoLink":"/gocolly/colly","commits":654},{"user":"codelucas","repo":"newspaper","url":"https://github.com/codelucas/newspaper","stars":13202,"description":"News, full-text, and article metadata extraction in Python 3. Advanced docs:","topics":["python","crawler","scraper","news","crawling","news-aggregator"],"repoLink":"/codelucas/newspaper","commits":651},{"user":"apify","repo":"crawlee","url":"https://github.com/apify/crawlee","stars":9225,"description":"Crawleeâ€”A web scraping and browser automation library for Node.js that helps you build reliable crawlers. Fast.","topics":["nodejs","javascript","npm","crawler","scraper","automation","typescript","web-crawler","headless","scraping","crawling","web-scraping","web-crawling","headless-chrome","apify","puppeteer","playwright"],"repoLink":"/apify/crawlee","commits":3890},{"user":"lorien","repo":"awesome-web-scraping","url":"https://github.com/lorien/awesome-web-scraping","stars":6017,"description":"List of libraries, tools and APIs for web scraping and data processing.","topics":["crawler","spider","scraping","crawling","web-scraping","captcha-recaptcha","webscraping","crawling-framework","scraping-framework","captcha-bypass","scraping-tool","crawling-tool","scraping-python","crawling-python"],"repoLink":"/lorien/awesome-web-scraping","commits":494},{"user":"MontFerret","repo":"ferret","url":"https://github.com/MontFerret/ferret","stars":5495,"description":"Declarative web scraping","topics":["go","cli","golang","crawler","chrome","data-mining","scraper","library","tool","dsl","scraping","crawling","query-language","scraping-websites","hacktoberfest","cdp","hacktoberfest2021"],"repoLink":"/MontFerret/ferret","commits":843},{"user":"yujiosaka","repo":"headless-chrome-crawler","url":"https://github.com/yujiosaka/headless-chrome-crawler","stars":5417,"description":"Distributed crawler powered by Headless Chrome","topics":["jquery","crawler","chrome","scraper","promise","scraping","crawling","chromium","headless-chrome","puppeteer"],"repoLink":"/yujiosaka/headless-chrome-crawler","commits":666},{"user":"go-rod","repo":"rod","url":"https://github.com/go-rod/rod","stars":4263,"description":"A Devtools driver for web automation and scraping","topics":["testing","go","golang","scraper","automation","web","chrome-devtools","headless","devtools","crawling","web-scraping","cdp","chrome-headless","rod","chrome-devtools-protocol","devtools-protocol","gorod"],"repoLink":"/go-rod/rod","commits":1260},{"user":"hakluke","repo":"hakrawler","url":"https://github.com/hakluke/hakrawler","stars":3997,"description":"Simple, fast web crawler designed for easy, quick discovery of endpoints and assets within a web application","topics":["osint","crawling","hacking","pentesting","recon","bugbounty","reconnaissance"],"repoLink":"/hakluke/hakrawler","commits":234},{"user":"hardkoded","repo":"puppeteer-sharp","url":"https://github.com/hardkoded/puppeteer-sharp","stars":2865,"description":"Headless Chrome .NET API","topics":["crawler","chrome","automation","csharp","crawling","chromium","e2e","webautomation","e2e-testing","puppeteer"],"repoLink":"/hardkoded/puppeteer-sharp","commits":1074},{"user":"apache","repo":"nutch","url":"https://github.com/apache/nutch","stars":2695,"description":"Apache Nutch is an extensible and scalable web crawler","topics":["java","hadoop","web-crawler","nutch","crawling","apache"],"repoLink":"/apache/nutch","commits":3404},{"user":"lorien","repo":"grab","url":"https://github.com/lorien/grab","stars":2322,"description":"Web Scraping Framework","topics":["python","crawler","framework","spider","asynchronous","network","python-library","scraping","crawling","http-client","python3","web-scraping","pycurl","urllib3"],"repoLink":"/lorien/grab","commits":2489},{"user":"transitive-bullshit","repo":"awesome-puppeteer","url":"https://github.com/transitive-bullshit/awesome-puppeteer","stars":2222,"description":"A curated list of awesome puppeteer resources.","topics":["automation","awesome","scraping","crawling","awesome-list","headless-chrome","puppeteer"],"repoLink":"/transitive-bullshit/awesome-puppeteer","commits":120},{"user":"zorlan","repo":"skycaiji","url":"https://github.com/zorlan/skycaiji","stars":1770,"description":"è“å¤©é‡‡é›†å™¨æ˜¯ä¸€æ¬¾å¼€æºå…è´¹çš„çˆ¬è™«ç³»ç»Ÿï¼Œä»…éœ€ç‚¹é€‰ç¼–è¾‘è§„åˆ™å³å¯é‡‡é›†æ•°æ®ï¼Œå¯è¿è¡Œåœ¨æœ¬åœ°ã€è™šæ‹Ÿä¸»æœºæˆ–äº‘æœåŠ¡å™¨ä¸­ï¼Œå‡ ä¹èƒ½é‡‡é›†æ‰€æœ‰ç±»å‹çš„ç½‘é¡µï¼Œæ— ç¼å¯¹æ¥å„ç±»CMSå»ºç«™ç¨‹åºï¼Œå…ç™»å½•å®æ—¶å‘å¸ƒæ•°æ®ï¼Œå…¨è‡ªåŠ¨æ— éœ€äººå·¥å¹²é¢„ï¼æ˜¯ç½‘é¡µå¤§æ•°æ®é‡‡é›†è½¯ä»¶ä¸­å®Œå…¨è·¨å¹³å°çš„äº‘ç«¯çˆ¬è™«ç³»ç»Ÿ","topics":["php","crawler","spider","crawling","webcrawler"],"repoLink":"/zorlan/skycaiji","commits":19},{"user":"roach-php","repo":"core","url":"https://github.com/roach-php/core","stars":1262,"description":"The complete web scraping toolkit for PHP.","topics":["php","crawling","web-scraping"],"repoLink":"/roach-php/core","commits":251},{"user":"edoardottt","repo":"cariddi","url":"https://github.com/edoardottt/cariddi","stars":1145,"description":"Take a list of domains, crawl urls and scan for endpoints, secrets, api keys, file extensions, tokens and more","topics":["go","golang","security","crawler","scraper","osint","crawling","penetration-testing","infosec","pentesting","recon","bugbounty","hacktoberfest","security-tools","endpoints","reconnaissance","secret-keys","endpoint-discovery","secrets-detection","asset-finder"],"repoLink":"/edoardottt/cariddi","commits":549},{"user":"lorey","repo":"mlscraper","url":"https://github.com/lorey/mlscraper","stars":1075,"description":"ğŸ¤– Scrape data from HTML websites automatically by just providing examples","topics":["html","crawler","machine-learning","scraper","scraping","crawling","crawler-python","extraction-engine"],"repoLink":"/lorey/mlscraper","commits":124},{"user":"needleworm","repo":"bhban_rpa","url":"https://github.com/needleworm/bhban_rpa","stars":885,"description":"<6ê°œì›” ì¹˜ ì—…ë¬´ë¥¼ í•˜ë£¨ ë§Œì— ëë‚´ëŠ” ì—…ë¬´ ìë™í™”(ìƒëŠ¥ì¶œíŒì‚¬, 2020)>ì˜ ì˜ˆì œ ì½”ë“œì…ë‹ˆë‹¤. íŒŒì´ì¬ì„ í•œ ë²ˆë„ ë°°ì›Œë³¸ ì  ì—†ëŠ” ë¶„ë“¤ì„ ìœ„í•œ ì˜ˆì œì´ë©°, ì—‘ì…€ë¶€í„° ë””ìì¸, ë§¤í¬ë¡œ, í¬ë¡¤ë§ê¹Œì§€ ì—…ë¬´ ìë™í™”ì™€ ê´€ë ¨ëœ ë‹¤ì–‘í•œ ë¶„ì•¼ ì˜ˆì œê°€ ì œê³µë©ë‹ˆë‹¤.","topics":["python","education","design","automation","crawling","rpa"],"repoLink":"/needleworm/bhban_rpa","commits":316},{"user":"NateScarlet","repo":"holiday-cn","url":"https://github.com/NateScarlet/holiday-cn","stars":862,"description":"ğŸ“…ğŸ‡¨ğŸ‡³ä¸­å›½æ³•å®šèŠ‚å‡æ—¥æ•°æ® è‡ªåŠ¨æ¯æ—¥æŠ“å–å›½åŠ¡é™¢å…¬å‘Š","topics":["data","natural-language-processing","crawling","china","holiday"],"repoLink":"/NateScarlet/holiday-cn","commits":329},{"user":"clemfromspace","repo":"scrapy-selenium","url":"https://github.com/clemfromspace/scrapy-selenium","stars":843,"description":"Scrapy middleware to handle javascript pages using selenium","topics":["crawling","selenium","scrapy"],"repoLink":"/clemfromspace/scrapy-selenium","commits":31}]